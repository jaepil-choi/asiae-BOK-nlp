{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from ekonlpy.sentiment import MPCK\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import os, sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTF-8\n",
      "cp1252\n"
     ]
    }
   ],
   "source": [
    "print(sys.stdout.encoding)\n",
    "print(sys.stdin.encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy BOK minutes text\n",
    "\n",
    "Code Attribution: 김현진T, Fininsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_sentences(section):\n",
    "    sentence_enders = re.compile(r'((?<=[함음됨임봄짐움])(\\s*\\n|\\.|;)|(?<=다)\\.)\\s*')\n",
    "    splits = list((m.start(), m.end()) for m in re.finditer(sentence_enders, section))\n",
    "    starts = [0] + [i[1] for i in splits]\n",
    "    ends = [i[0] for i in splits]\n",
    "    sentences = [section[start:end] for start, end in zip(starts[:-1], ends)]\n",
    "    for i, s in enumerate(sentences):\n",
    "        sentences[i] = (s.replace('\\n', ' ').replace(' ', ' ')) + '.'\n",
    "\n",
    "    text = '\\n'.join(sentences) if len(sentences) > 0 else ''\n",
    "    return sentences, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_minutes(minutes):\n",
    "\n",
    "    pos = re.search('(.?국내외\\s?경제\\s?동향.?과 관련하여,?|\\(가\\).+경제전망.*|\\(가\\) 국내외 경제동향 및 평가)\\n?\\s*일부 위원은', minutes, re.MULTILINE)\n",
    "    s1 = pos.start() if pos else -1\n",
    "    pos = re.search('(.?외환.?국제금융\\s?동향.?과 관련하여.*|\\(나\\) 외환.국제금융\\s?(및 금융시장)?\\s?동향)\\n?\\s*(일부 위원은|대부분의 위원들은)', minutes,re.MULTILINE)\n",
    "    s2 = pos.start() if pos else -1\n",
    "    pos = re.search('(.?금융시장\\s?동향.?과 관련하여,?|\\(다\\) 금융시장\\s?동향)\\n?\\s*일부 위원은', minutes, re.MULTILINE)\n",
    "    s3 = pos.start() if pos else -1\n",
    "    pos = re.search('((\\((다|라)\\) )?.?통화정책\\s?방향.?에 관한 토론,?|이상과 같은 의견\\s?교환을 바탕으로.*통화정책\\s?방향.*에.*토론.*)\\n?', minutes,re.MULTILINE)\n",
    "    s4 = pos.start() if pos else -1\n",
    "    pos = re.search('(\\(4\\) 정부측 열석자 발언.*)\\n?', minutes, re.MULTILINE)\n",
    "    s5 = pos.start() if pos else -1\n",
    "    pos = re.search('(\\(.*\\) 한국은행 기준금리 결정에 관한 위원별 의견\\s?개진|이상과 같은 토론에 이어 .* 관한 위원별 의견개진이 있었음.*)\\n?', minutes,re.MULTILINE)\n",
    "    s6 = pos.start() if pos else -1\n",
    "    positer = re.finditer('(\\(\\s?.*\\s?\\) ()(심의결과|토의결론))\\n?', minutes, re.MULTILINE)\n",
    "    s7 = [pos.start() for pos in positer if pos.start() > s6]\n",
    "    s7 = s7[0] if s7 else -1\n",
    "\n",
    "    # 국내외 경제동향\n",
    "    bos = s1\n",
    "    eos = s2\n",
    "    section = minutes[bos:eos] if bos >= 0 or eos >= 0 else ''\n",
    "    pos = re.search('(일부|대부분의) 위원들?은', section, re.MULTILINE)\n",
    "    bos = pos.start() if pos else -1\n",
    "    section = section[bos:] if bos >= 0 else section\n",
    "    section1, section1_txt = tidy_sentences(section)\n",
    "\n",
    "    # 외환․국제금융 동향\n",
    "    bos = s2\n",
    "    eos = s3 if s3 >= 0 else s4\n",
    "    section = minutes[bos:eos] if bos >= 0 or eos >= 0 else ''\n",
    "    pos = re.search('(일부|대부분의) 위원들?은', section, re.MULTILINE)\n",
    "    bos = pos.start() if pos else -1\n",
    "    section = section[bos:] if bos >= 0 else section\n",
    "    section2, section2_txt = tidy_sentences(section)\n",
    "    #print(section)\n",
    "\n",
    "    # 금융시장 동향\n",
    "    bos = s3\n",
    "    eos = s4\n",
    "    section = minutes[bos:eos] if bos >= 0 or eos >= 0 else ''\n",
    "    pos = re.search('(일부|대부분의) 위원들?은', section, re.MULTILINE)\n",
    "    bos = pos.start() if pos else -1\n",
    "    section = section[bos:] if bos >= 0 else section\n",
    "    section3, section3_txt = tidy_sentences(section)\n",
    "\n",
    "    # 통화정책방향\n",
    "    bos = s4\n",
    "    eos = s5 if s5 >= 0 else s6 if s6 >= 0 else s7\n",
    "    section = minutes[bos:eos] if bos >= 0 or eos >= 0 else ''\n",
    "    pos = re.search('(일부|대부분의) 위원들?은', section, re.MULTILINE)\n",
    "    bos = pos.start() if pos else -1\n",
    "    section = section[bos:] if bos >= 0 else section\n",
    "    section4, section4_txt = tidy_sentences(section)\n",
    "\n",
    "    # 위원별 의견 개진\n",
    "    bos = s6\n",
    "    eos = s7\n",
    "    section = minutes[bos:eos] if bos >= 0 or eos >= 0 else ''\n",
    "    pos = re.search('(일부|대부분의) 위원들?은', section, re.MULTILINE)\n",
    "    bos = pos.start() if pos else -1\n",
    "    section = section[bos:] if bos >= 0 else section\n",
    "    section5, section5_txt = tidy_sentences(section)\n",
    "\n",
    "    # 정부측 열석자 발언\n",
    "    bos = s5\n",
    "    eos = s6\n",
    "    section = minutes[bos:eos] if bos >= 0 or eos >= 0 else ''\n",
    "    pos = re.search('정부측 열석자 발언', section, re.MULTILINE)\n",
    "    bos = pos.end() + 1 if pos else -1\n",
    "    section = section[bos:] if bos >= 0 else section\n",
    "    section6, section6_txt = tidy_sentences(section)\n",
    "\n",
    "    sections = ['Economic Situation', 'Foreign Currency', 'Financial Markets',\n",
    "                'Monetary Policy', 'Participants’ Views', 'Government’s View']\n",
    "    section_texts = (section1, section2, section3, section4, section5, section6)\n",
    "\n",
    "\n",
    "    return sections, section_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korean stop words from here: \n",
    "https://www.ranks.nl/stopwords/korean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStopwords(data_path) :\n",
    "    f = open(data_path, 'r',-1,'utf-8')\n",
    "    stop_word = []\n",
    "\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        stop_word.append(line.strip())\n",
    "        if not line: break\n",
    "\n",
    "    return stop_word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data_files/stop_wd.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아', '휴', '아이구', '아이쿠', '아이고', '어', '나', '우리', '저희', '따라']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_word = getStopwords(data_path)\n",
    "stop_word[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2ngram(text) :\n",
    "    mpck = MPCK()\n",
    "    \n",
    "    tokens = mpck.tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token.split('/')[0])>1]\n",
    "    tokens = [token for token in tokens if token.split('/')[0] not in stop_word]\n",
    "    \n",
    "    ngrams = mpck.ngramize(tokens)\n",
    "\n",
    "    return tokens+ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(source_folder=\"./data_files/BOK_minutes/pdf2txt/\", output_file=\"./data_files/BOK_minutes/pkl/\") :\n",
    "    # 지정 폴더 내 파일 목록 조회 (파일만)\n",
    "    txt_files = [f for f in os.listdir(source_folder) if os.path.isfile(os.path.join(source_folder, f))]\n",
    "    txt_files.sort()\n",
    "    df = pd.DataFrame(columns=['date', 'minutes'])\n",
    "    df[\"Economic Situation\"] = \"\"\n",
    "    df[\"Foreign Currency\"] = \"\"\n",
    "    df[\"Financial Markets\"] = \"\"\n",
    "    df[\"Monetary Policy\"] = \"\"\n",
    "    df[\"Participant Views\"] = \"\"\n",
    "    df[\"Government View\"] = \"\"\n",
    "\n",
    "    df[\"Economic Situation count\"] = \"\"\n",
    "    df[\"Foreign Currency count\"] = \"\"\n",
    "    df[\"Financial Markets count\"] = \"\"\n",
    "    df[\"Monetary Policy count\"] = \"\"\n",
    "    df[\"Participant Views count\"] = \"\"\n",
    "    df[\"Government View count\"] = \"\"\n",
    "    df['ngrams'] =\"\"\n",
    "    \n",
    "\n",
    "    for txt_file in txt_files :\n",
    "        try :\n",
    "            with open(source_folder + txt_file, 'r',encoding='utf-8') as f :\n",
    "                txt = f.read()\n",
    "                sections, section_texts = preprocess_minutes(txt)\n",
    "\n",
    "                print(txt_file)\n",
    "\n",
    "                ngrams = []\n",
    "                for section_text in section_texts[1:3] :\n",
    "                    for sentence in section_text :\n",
    "                        ngrams.append(','.join(text2ngram(sentence)))\n",
    "\n",
    "                #print('@@@'.join(ngrams))\n",
    "                #break\n",
    "\n",
    "                df.loc[len(df)] = [txt_file.split('_')[0],\n",
    "                                   txt,\n",
    "                                   '@@@'.join(section_texts[0]),\n",
    "                                   '@@@'.join(section_texts[1]),\n",
    "                                   '@@@'.join(section_texts[2]),\n",
    "                                   '@@@'.join(section_texts[3]),\n",
    "                                   '@@@'.join(section_texts[4]),\n",
    "                                   '@@@'.join(section_texts[5]),\n",
    "                                   len(section_texts[0]),\n",
    "                                   len(section_texts[1]),\n",
    "                                   len(section_texts[2]),\n",
    "                                   len(section_texts[3]),\n",
    "                                   len(section_texts[4]),\n",
    "                                   len(section_texts[5]),\n",
    "                                   '@@@'.join(ngrams)]\n",
    "        except :\n",
    "            pass\n",
    "    \n",
    "    df.to_pickle(output_file)\n",
    "        \n",
    "    print(df.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
